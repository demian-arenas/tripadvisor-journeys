{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duck_con = duckdb.connect('tripadvisor.db')\n",
    "user_visits = duck_con.execute(\n",
    "    \"\"\"SELECT userid, COUNT(0) total_visits\n",
    "                    FROM clickstream2\n",
    "                 WHERE visit_tripadvisor = TRUE\n",
    "                 GROUP BY userid\"\"\"\n",
    ").df()\n",
    "user_visits.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_time_between_visits = duck_con.execute(\"\"\"WITH prebase_first_visit AS (\n",
    "                        SELECT userid, eventdate, date_casted, event_order\n",
    "                        FROM clickstream2\n",
    "                        WHERE visit_tripadvisor = TRUE\n",
    "                        AND day_visited_number = 1\n",
    "                    ), second_visit AS (\n",
    "                        SELECT userid, eventdate, date_casted, event_order, day_visited_number\n",
    "                        FROM clickstream2\n",
    "                        WHERE clickstream2.visit_tripadvisor = TRUE\n",
    "                        AND day_visited_number = 2\n",
    "                    )\n",
    "                 SELECT prebase_first_visit.userid, DATEDIFF('day', prebase_first_visit.date_casted, second_visit.date_casted) AS days_between_visits\n",
    "                    FROM prebase_first_visit\n",
    "                    INNER JOIN second_visit ON prebase_first_visit.userid = second_visit.userid\"\"\"\n",
    ").df()\n",
    "users_time_between_visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the cumulative percent of users from day 1 to day 30 \n",
    "all_days = users_time_between_visits['days_between_visits'].value_counts().sort_index().reset_index()\n",
    "all_days.columns = ['days_between_visits', 'count']\n",
    "all_days['cumulative_percent'] = round((all_days['count'].cumsum()/len(users_time_between_visits))*100, 2)\n",
    "\n",
    "only_30_days = all_days[all_days['days_between_visits'] <= 30]\n",
    "\n",
    "# plot with plotly the cumulative percent of users from day 1 to day 30\n",
    "# Add a annotation only when the cumulative percent is 80%\n",
    "\n",
    "fig = px.line(\n",
    "    only_30_days,\n",
    "    x=\"days_between_visits\",\n",
    "    y=\"cumulative_percent\",\n",
    "    title=\"Cumulative percent of users from day 1 to day 30\",\n",
    ")\n",
    "# Set fig axis Y from 0 to 100 and X from 0 to 30\n",
    "fig.update_yaxes(range=[0, 100])\n",
    "fig.update_xaxes(range=[0, 30])\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=only_30_days[\"days_between_visits\"],\n",
    "        y=only_30_days[\"cumulative_percent\"]\n",
    "    )\n",
    ")\n",
    "users_80_percent = only_30_days[only_30_days[\"cumulative_percent\"] >= 80]\n",
    "x_value = users_80_percent[\"days_between_visits\"].min()\n",
    "y_value = users_80_percent[\"cumulative_percent\"].min()\n",
    "fig.add_annotation(\n",
    "    x=x_value,\n",
    "    y=y_value,\n",
    "    text=f\"80% of users have returned in {x_value} days\",\n",
    "    showarrow=True,\n",
    "    arrowhead=1,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_between_before_first_visit = duck_con.execute(\"\"\"\n",
    "WITH prebase_first_visit AS (\n",
    "    SELECT userid,\n",
    "        date_casted,\n",
    "        event_order\n",
    "    FROM clickstream2\n",
    "    WHERE visit_tripadvisor = TRUE\n",
    "        AND day_visited_number = 1\n",
    ")\n",
    "SELECT first_event.userid,\n",
    "    first_event.date_casted first_date_event,\n",
    "    prebase_first_visit.date_casted first_date_visit,\n",
    "    DATE_DIFF('day', first_event.date_casted, prebase_first_visit.date_casted) days_between\n",
    "FROM clickstream2 first_event\n",
    "INNER JOIN prebase_first_visit ON first_event.userid = prebase_first_visit.userid\n",
    "WHERE first_event.event_order = 1\"\"\"\n",
    ").df()\n",
    "\n",
    "# show the cumulative percent of users from day 1 to day 30 \n",
    "all_days = days_between_before_first_visit['days_between'].value_counts().sort_index().reset_index()\n",
    "all_days.columns = ['days_between', 'count']\n",
    "all_days['cumulative_percent'] = round((all_days['count'].cumsum()/len(days_between_before_first_visit))*100, 2)\n",
    "\n",
    "until_n_day = 60\n",
    "only_30_days = all_days[all_days['days_between'] <= until_n_day]\n",
    "\n",
    "# plot with plotly the cumulative percent of users from day 1 to day until_n_day\n",
    "# Add a annotation only when the cumulative percent is 80%\n",
    "\n",
    "fig = px.line(\n",
    "    only_30_days,\n",
    "    x=\"days_between\",\n",
    "    y=\"cumulative_percent\",\n",
    "    title=\"Cumulative percent of users from day 1 to day 30\",\n",
    ")\n",
    "# Set fig axis Y from 0 to 100 and X from 0 to 30\n",
    "fig.update_yaxes(range=[0, 100])\n",
    "fig.update_xaxes(range=[0, until_n_day])\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=only_30_days[\"days_between\"],\n",
    "        y=only_30_days[\"cumulative_percent\"]\n",
    "    )\n",
    ")\n",
    "users_80_percent = only_30_days[only_30_days[\"cumulative_percent\"] >= 20]\n",
    "x_value = users_80_percent[\"days_between\"].min()\n",
    "y_value = users_80_percent[\"cumulative_percent\"].min()\n",
    "fig.add_annotation(\n",
    "    x=x_value,\n",
    "    y=y_value,\n",
    "    text=f\"20% of users have first visit in {x_value} days\",\n",
    "    showarrow=True,\n",
    "    arrowhead=1,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_between_before_first_visit_and_last_session = duck_con.execute(\"\"\"\n",
    "WITH prebase_first_visit AS (\n",
    "    SELECT userid,\n",
    "        date_casted,\n",
    "        event_order\n",
    "    FROM clickstream2\n",
    "    WHERE visit_tripadvisor = TRUE\n",
    "        AND day_visited_number = 1\n",
    "),\n",
    "previous_session AS (\n",
    "SELECT clickstream2.userid,\n",
    "    MAX(clickstream2.date_casted) previous_date_casted\n",
    "FROM clickstream2\n",
    "INNER JOIN prebase_first_visit ON clickstream2.userid = prebase_first_visit.userid\n",
    "WHERE clickstream2.date_casted < prebase_first_visit.date_casted\n",
    "GROUP BY clickstream2.userid\n",
    ")\n",
    "SELECT prebase_first_visit.userid,\n",
    "    previous_session.previous_date_casted,\n",
    "    prebase_first_visit.date_casted first_date_visit,\n",
    "    DATE_DIFF('day', previous_session.previous_date_casted, prebase_first_visit.date_casted) days_between\n",
    "FROM prebase_first_visit \n",
    "INNER JOIN previous_session ON previous_session.userid = prebase_first_visit.userid\"\"\"\n",
    ").df()\n",
    "\n",
    "# show the cumulative percent of users from day 1 to day 30 \n",
    "all_days = days_between_before_first_visit_and_last_session['days_between'].value_counts().sort_index().reset_index()\n",
    "all_days.columns = ['days_between', 'count']\n",
    "all_days['cumulative_percent'] = round((all_days['count'].cumsum()/len(days_between_before_first_visit_and_last_session))*100, 2)\n",
    "\n",
    "until_n_day = 60\n",
    "only_30_days = all_days[all_days['days_between'] <= until_n_day]\n",
    "\n",
    "# plot with plotly the cumulative percent of users from day 1 to day until_n_day\n",
    "# Add a annotation only when the cumulative percent is 80%\n",
    "\n",
    "fig = px.line(\n",
    "    only_30_days,\n",
    "    x=\"days_between\",\n",
    "    y=\"cumulative_percent\",\n",
    "    title=\"How many days pass from the first visit to the previous day session in traffic?\",\n",
    ")\n",
    "# Set fig axis Y from 0 to 100 and X from 0 to 30\n",
    "fig.update_yaxes(range=[0, 100])\n",
    "fig.update_xaxes(range=[0, until_n_day])\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=only_30_days[\"days_between\"],\n",
    "        y=only_30_days[\"cumulative_percent\"]\n",
    "    )\n",
    ")\n",
    "# Set percent of 2 standard deviation\n",
    "users_80_percent = only_30_days[only_30_days[\"cumulative_percent\"] >= 95]\n",
    "x_value = users_80_percent[\"days_between\"].min()\n",
    "y_value = users_80_percent[\"cumulative_percent\"].min()\n",
    "fig.add_annotation(\n",
    "    x=x_value,\n",
    "    y=y_value,\n",
    "    text=f\"95% of users have first visit in {x_value} days\",\n",
    "    showarrow=True,\n",
    "    arrowhead=1,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all events of users before the first visit event\n",
    "users_events_before_first_visit = duck_con.execute(\n",
    "    \"\"\"WITH prebase_first_visit AS (\n",
    "                        SELECT userid, eventdate, date_casted, event_order,\n",
    "                            (date_casted - '5 days'::interval) AS session_before\n",
    "                        FROM clickstream2\n",
    "                        WHERE visit_tripadvisor = TRUE\n",
    "                        AND visit_number = 1\n",
    "                        ORDER BY eventdate\n",
    "                        LIMIT 25\n",
    "                    )\n",
    "                    SELECT clickstream2.userid,\n",
    "                        clickstream2.eventdate,\n",
    "                        clickstream2.eventtimestamp,\n",
    "                        clickstream2.date_casted,\n",
    "                        clickstream2.referrerurl,\n",
    "                        clickstream2.targeturl,\n",
    "                        clickstream2.event_order\n",
    "                    FROM clickstream2\n",
    "                    INNER JOIN prebase_first_visit ON clickstream2.userid = prebase_first_visit.userid\n",
    "                    WHERE clickstream2.event_order < prebase_first_visit.event_order\n",
    "                    AND clickstream2.eventdate >= prebase_first_visit.session_before\n",
    "                    AND clickstream2.userid = '111a0458-bd4b-4781-ba21-2875fee04b86'\n",
    "                    ORDER BY clickstream2.userid, clickstream2.event_order\"\"\"\n",
    ").df()\n",
    "users_events_before_first_visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = duck_con.execute(\n",
    "    \"\"\"WITH prebase_first_visit AS (\n",
    "    SELECT DISTINCT userid,\n",
    "        eventdate,\n",
    "        date_casted,\n",
    "        event_order,\n",
    "        (date_casted - '1 month'::interval) AS one_month_before\n",
    "    FROM clickstream2\n",
    "    WHERE visit_tripadvisor = TRUE\n",
    "        AND visit_number = 1\n",
    "    ORDER BY eventdate\n",
    "    LIMIT 25\n",
    "),\n",
    "data_before_first_visit AS (\n",
    "    SELECT clickstream2.userid,\n",
    "        clickstream2.date_casted,\n",
    "        clickstream2.event_order,\n",
    "        clickstream2.referrerurl previous_url,\n",
    "        clickstream2.targeturl current_url,\n",
    "        LEAD(clickstream2.targeturl) OVER (\n",
    "            PARTITION BY clickstream2.userid \n",
    "            ORDER BY clickstream2.event_order\n",
    "        ) AS next_target_url\n",
    "    FROM clickstream2\n",
    "    INNER JOIN prebase_first_visit ON clickstream2.userid = prebase_first_visit.userid\n",
    "    WHERE clickstream2.event_order < prebase_first_visit.event_order\n",
    "    AND clickstream2.eventdate >= prebase_first_visit.one_month_before\n",
    "),\n",
    "filtered_data AS (\n",
    "    SELECT userid,\n",
    "           date_casted,\n",
    "           event_order,\n",
    "           previous_url,\n",
    "           current_url\n",
    "    FROM data_before_first_visit\n",
    "    WHERE current_url != next_target_url OR next_target_url IS NULL\n",
    ")\n",
    "\n",
    "SELECT userid,\n",
    "       date_casted,\n",
    "       current_url AS url,\n",
    "       ROW_NUMBER() OVER (PARTITION BY userid ORDER BY event_order) AS sequence\n",
    "FROM filtered_data\n",
    "ORDER BY userid, sequence;\n",
    "\"\"\"\n",
    ").df()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duck_con.execute(\"\"\"DROP TABLE user_sequence\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duck_con.execute(\"\"\"CREATE TABLE IF NOT EXISTS user_sequence AS WITH prebase_first_visit AS (\n",
    "    SELECT DISTINCT userid,\n",
    "        eventdate,\n",
    "        date_casted,\n",
    "        event_order,\n",
    "        (date_casted - '5 days'::interval) AS session_before\n",
    "    FROM clickstream2\n",
    "    WHERE visit_tripadvisor = TRUE\n",
    "        AND visit_number = 1\n",
    "        AND have_problem_with_timestamp = FALSE\n",
    "    ORDER BY eventdate\n",
    "),\n",
    "data_before_first_visit AS (\n",
    "    SELECT clickstream2.userid,\n",
    "        clickstream2.date_casted,\n",
    "        clickstream2.event_order,\n",
    "        clickstream2.referrerurl previous_url,\n",
    "        clickstream2.targeturl current_url,\n",
    "        LEAD(clickstream2.targeturl) OVER (\n",
    "            PARTITION BY clickstream2.userid\n",
    "            ORDER BY clickstream2.event_order\n",
    "        ) AS next_target_url\n",
    "    FROM clickstream2\n",
    "        INNER JOIN prebase_first_visit ON clickstream2.userid = prebase_first_visit.userid\n",
    "    WHERE clickstream2.event_order < prebase_first_visit.event_order\n",
    "        AND clickstream2.eventdate >= prebase_first_visit.session_before\n",
    "        AND clickstream2.have_problem_with_timestamp = FALSE\n",
    "),\n",
    "filtered_data AS (\n",
    "    SELECT userid,\n",
    "        date_casted,\n",
    "        event_order,\n",
    "        previous_url,\n",
    "        current_url\n",
    "    FROM data_before_first_visit\n",
    "    WHERE current_url != next_target_url\n",
    "        OR next_target_url IS NULL\n",
    ")\n",
    "SELECT userid,\n",
    "    date_casted,\n",
    "    current_url AS url,\n",
    "    ROW_NUMBER() OVER (\n",
    "        PARTITION BY userid\n",
    "        ORDER BY event_order\n",
    "    ) AS sequence,\n",
    "    ROW_NUMBER() OVER (\n",
    "        PARTITION BY userid\n",
    "        ORDER BY event_order DESC\n",
    "    ) AS reverse_sequence\n",
    "FROM filtered_data\n",
    "ORDER BY userid,\n",
    "    sequence;\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duck_con.execute(\"\"\"SELECT userid,\n",
    "    event_order,\n",
    "    date_casted,\n",
    "    referrerurl,\n",
    "    regexp_extract(referrerurl, '^(?:https?:\\/\\/)?(?:[^@\\/\\n]+@)?(?:www\\.)?([^:\\/\\n]+)', 1) AS previous_domain,\n",
    "    targeturl,\n",
    "    regexp_extract(targeturl, '^(?:https?:\\/\\/)?(?:[^@\\/\\n]+@)?(?:www\\.)?([^:\\/\\n]+)', 1) AS current_domain\n",
    "FROM clickstream2\n",
    "LIMIT 10;\"\"\"\n",
    ").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duck_con.execute(\"\"\"DROP TABLE user_sequence_domains\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duck_con.execute(\"\"\"CREATE TABLE IF NOT EXISTS user_sequence_domains AS WITH prebase_first_visit AS (\n",
    "    SELECT DISTINCT userid,\n",
    "        eventdate,\n",
    "        date_casted,\n",
    "        event_order,\n",
    "        (date_casted - '5 days'::interval) AS session_before\n",
    "    FROM clickstream2\n",
    "    WHERE visit_tripadvisor = TRUE\n",
    "        AND visit_number = 1\n",
    "        AND clickstream2.have_problem_with_timestamp = FALSE\n",
    "    ORDER BY eventdate\n",
    "),\n",
    "domain_extraction AS (\n",
    "    SELECT clickstream2.userid,\n",
    "        clickstream2.event_order,\n",
    "        clickstream2.date_casted,\n",
    "        regexp_extract(referrerurl, '^(?:https?:\\/\\/)?(?:[^@\\/\\n]+@)?(?:www\\.)?([^:\\/\\n]+)', 1) AS previous_domain,\n",
    "        regexp_extract(targeturl, '^(?:https?:\\/\\/)?(?:[^@\\/\\n]+@)?(?:www\\.)?([^:\\/\\n]+)', 1) AS current_domain\n",
    "    FROM clickstream2\n",
    "        INNER JOIN prebase_first_visit p ON clickstream2.userid = p.userid\n",
    "    WHERE clickstream2.event_order < p.event_order\n",
    "        AND clickstream2.date_casted >= p.session_before\n",
    "        AND clickstream2.have_problem_with_timestamp = FALSE\n",
    "),\n",
    "data_before_first_visit AS (\n",
    "    SELECT d.userid,\n",
    "        d.date_casted,\n",
    "        d.event_order,\n",
    "        d.previous_domain,\n",
    "        d.current_domain,\n",
    "        LEAD(d.current_domain) OVER (\n",
    "            PARTITION BY d.userid\n",
    "            ORDER BY d.event_order\n",
    "        ) AS next_domain\n",
    "    FROM domain_extraction d\n",
    "),\n",
    "filtered_data AS (\n",
    "    SELECT userid,\n",
    "        date_casted,\n",
    "        event_order,\n",
    "        previous_domain,\n",
    "        current_domain\n",
    "    FROM data_before_first_visit\n",
    "    WHERE (\n",
    "        current_domain != next_domain\n",
    "        AND current_domain IS NOT NULL\n",
    "        AND current_domain != ''\n",
    "    )\n",
    "    OR next_domain IS NULL\n",
    ")\n",
    "SELECT userid,\n",
    "    date_casted,\n",
    "    current_domain AS domain,\n",
    "    ROW_NUMBER() OVER (\n",
    "        PARTITION BY userid\n",
    "        ORDER BY event_order\n",
    "    ) AS sequence,\n",
    "    ROW_NUMBER() OVER (\n",
    "        PARTITION BY userid\n",
    "        ORDER BY event_order DESC\n",
    "    ) AS reverse_sequence\n",
    "FROM filtered_data\n",
    "ORDER BY userid,\n",
    "    sequence\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_id = '111a0458-bd4b-4781-ba21-2875fee04b86'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_user_sequence = duck_con.execute(f\"\"\"SELECT userid,\n",
    "    sequence,\n",
    "    reverse_sequence,\n",
    "    date_casted,\n",
    "    domain\n",
    "FROM user_sequence_domains\n",
    "WHERE userid = '{test_user_id}'\n",
    "ORDER BY sequence;\"\"\").df()\n",
    "check_user_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_user_sequence = duck_con.execute(f\"\"\"SELECT userid,\n",
    "    sequence,\n",
    "    reverse_sequence,\n",
    "    date_casted,\n",
    "    url\n",
    "FROM user_sequence\n",
    "WHERE userid = '{test_user_id}'\n",
    "ORDER BY sequence;\"\"\").df()\n",
    "check_user_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top urls visited before tripadvisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duck_con.execute(\"\"\"SELECT url, COUNT(0) as count \n",
    "FROM user_sequence\n",
    "GROUP BY url\n",
    "ORDER BY count DESC\n",
    "LIMIT 10;\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duck_con.execute(\"\"\"SELECT domain, COUNT(0) as count \n",
    "FROM user_sequence_domains\n",
    "GROUP BY domain\n",
    "ORDER BY count DESC\n",
    "LIMIT 250;\n",
    "\"\"\").df()[['domain']].to_csv('domains.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "websites_categories = {\n",
    "    \"Search Engines\": [\"google.com\", \"bing.com\", \"duckduckgo.com\", \"yahoo.com\", \"ecosia.org\"],\n",
    "    \"Social Media\": [\"facebook.com\", \"instagram.com\", \"twitter.com\", \"tumblr.com\", \"linkedin.com\", \"pinterest.com\", \"tiktok.com\", \"messenger.com\", \"discord.com\", \"whatsapp.com\", \"reddit.com\", \"snapchat.com\"],\n",
    "    \"Streaming & Entertainment\": [\"youtube.com\", \"netflix.com\", \"hulu.com\", \"hbomax.com\", \"spotify.com\", \"vimeo.com\"],\n",
    "    \"E-commerce\": [\"amazon.com\", \"ebay.com\", \"walmart.com\", \"etsy.com\", \"aliexpress.com\", \"bestbuy.com\", \"lowes.com\", \"kohls.com\", \"macys.com\", \"hotels.com\", \"rakuten.com\", \"wayfair.com\", \"gap.com\", \"shein.com\"],\n",
    "    \"News & Media\": [\"nytimes.com\", \"cnn.com\", \"foxnews.com\", \"washingtonpost.com\", \"wsj.com\", \"usatoday.com\", \"bbc.com\", \"cnbc.com\", \"nypost.com\", \"forbes.com\", \"theguardian.com\", \"businessinsider.com\", \"buzzfeed.com\"],\n",
    "    \"Technology & Web Services\": [\"microsoft.com\", \"apple.com\", \"github.com\", \"adobe.com\", \"slack.com\", \"salesforce.com\", \"dropbox.com\", \"godaddy.com\", \"cloudfront.net\", \"wix.com\"],\n",
    "    \"Education\": [\"wikipedia.org\", \"instructure.com\", \"quizlet.com\", \"blackboard.com\", \"chegg.com\", \"harvard.edu\", \"ucdavis.edu\", \"usc.edu\", \"stanford.edu\", \"rutgers.edu\", \"umich.edu\", \"stanford.edu\", \"columbia.edu\", \"cuny.edu\", \"ufl.edu\", \"wisc.edu\", \"ucf.edu\", \"pitt.edu\", \"washington.edu\", \"duke.edu\", \"yale.edu\", \"northwestern.edu\", \"miami.edu\", \"wustl.edu\", \"utexas.edu\", \"nyu.edu\", \"arizona.edu\", \"studentdoctor.net\", \"squarespace.com\", \"ucla.edu\", \"upenn.edu\", \"umn.edu\"],\n",
    "    \"Health\": [\"nih.gov\", \"mayoclinic.org\", \"webmd.com\", \"cdc.gov\"],\n",
    "    \"Finance & Banking\": [\"chase.com\", \"bankofamerica.com\", \"paypal.com\", \"americanexpress.com\", \"fidelity.com\", \"wellsfargo.com\", \"capitalone.com\", \"intuit.com\", \"citi.com\", \"vanguard.com\", \"schwab.com\", \"robinhood.com\"],\n",
    "    \"Business & Productivity\": [\"office.com\", \"zoom.us\", \"slack.com\", \"salesforce.com\", \"glassdoor.com\"],\n",
    "    \"Ads & Marketing\": [\"doubleclick.net\", \"googlesyndication.com\", \"googleadservices.com\"],\n",
    "    \"Online Communities & Forums\": [\"quora.com\", \"fandom.com\", \"medium.com\", \"stackexchange.com\", \"reddit.com\", \"studentdoctor.net\"],\n",
    "    \"Travel & Accommodation\": [\"expedia.com\", \"airbnb.com\", \"booking.com\", \"priceline.com\", \"kayak.com\", \"flyfrontier.com\", \"delta.com\"],\n",
    "    \"Government\": [\"irs.gov\", \"state.gov\", \"uscis.gov\", \"va.gov\"],\n",
    "}\n",
    "\n",
    "\n",
    "# Create a table with the categories\n",
    "duck_con.execute(\"\"\"DROP TABLE IF EXISTS websites_categories\"\"\")\n",
    "duck_con.execute(\"\"\"DROP SEQUENCE IF EXISTS website_id\"\"\")\n",
    "\n",
    "duck_con.sql(\"\"\"CREATE SEQUENCE website_id START 1;\"\"\")\n",
    "\n",
    "duck_con.execute(\"\"\"CREATE TABLE IF NOT EXISTS websites_categories (\n",
    "    id INT DEFAULT NEXTVAL('website_id'),\n",
    "    domain VARCHAR(255) NOT NULL,\n",
    "    category VARCHAR(255) NOT NULL\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "for category, domains in websites_categories.items():\n",
    "    for domain in domains:\n",
    "        duck_con.execute(f\"\"\"INSERT INTO websites_categories (domain, category) VALUES ('{domain}', '{category}');\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duck_con.execute(\"\"\"WITH prebase AS (\n",
    "    SELECT domain,\n",
    "        COUNT(0) as total_events\n",
    "    FROM user_sequence_domains\n",
    "    GROUP BY domain\n",
    "    ORDER BY 2 DESC\n",
    "    LIMIT 1000\n",
    ")\n",
    "SELECT domain,\n",
    "    CASE\n",
    "        WHEN LENGTH(domain) - LENGTH(REPLACE(domain, '.', '')) >= 2 THEN\n",
    "            CONCAT(\n",
    "                REVERSE(SUBSTRING(\n",
    "                    REVERSE(domain),\n",
    "                    position('.' in REVERSE(domain)) + 1,\n",
    "                    position('.' in SUBSTRING(REVERSE(domain), position('.' in REVERSE(domain)) + 1)) -1 \n",
    "                )),\n",
    "                REVERSE(SUBSTRING(\n",
    "                    REVERSE(domain),\n",
    "                    1,\n",
    "                    position('.' in REVERSE(domain))\n",
    "                ))\n",
    "            )\n",
    "        ELSE domain\n",
    "    END AS base_domain\n",
    "FROM prebase\n",
    "WHERE LENGTH(domain) - LENGTH(REPLACE(domain, '.', '')) >= 2\n",
    "ORDER BY total_events DESC;\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duck_con.execute(\"\"\"UPDATE user_sequence_domains\n",
    "SET domain = CASE\n",
    "        WHEN LENGTH(domain) - LENGTH(REPLACE(domain, '.', '')) >= 2 THEN\n",
    "            CONCAT(\n",
    "                REVERSE(SUBSTRING(\n",
    "                    REVERSE(domain),\n",
    "                    position('.' in REVERSE(domain)) + 1,\n",
    "                    position('.' in SUBSTRING(REVERSE(domain), position('.' in REVERSE(domain)) + 1)) -1 \n",
    "                )),\n",
    "                REVERSE(SUBSTRING(\n",
    "                    REVERSE(domain),\n",
    "                    1,\n",
    "                    position('.' in REVERSE(domain))\n",
    "                ))\n",
    "            )\n",
    "        ELSE domain\n",
    "    END\n",
    "WHERE LENGTH(domain) - LENGTH(REPLACE(domain, '.', '')) >= 2;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_treemap = duck_con.execute(\"\"\"\n",
    "WITH prebase_domains_categories AS (\n",
    "    SELECT user_sequence_domains.domain, \n",
    "        CASE WHEN category IS NULL THEN 'Other' ELSE category END AS category,\n",
    "        COUNT(0) as total_events\n",
    "FROM user_sequence_domains\n",
    "LEFT JOIN websites_categories ON user_sequence_domains.domain = websites_categories.domain\n",
    "GROUP BY user_sequence_domains.domain, 2\n",
    ")\n",
    "SELECT category, CAST(SUM(total_events) AS INT) as total_events\n",
    "FROM prebase_domains_categories\n",
    "GROUP BY category\n",
    "ORDER BY total_events DESC\n",
    "LIMIT 50;\n",
    "\"\"\").df()\n",
    "\n",
    "child_treemap = duck_con.execute(\"\"\"\n",
    "WITH prebase_domains_categories AS (\n",
    "    SELECT user_sequence_domains.domain,\n",
    "        CASE WHEN category IS NULL THEN 'Other' ELSE category END AS category,\n",
    "        COUNT(0) as total_events\n",
    "FROM user_sequence_domains\n",
    "LEFT JOIN websites_categories ON user_sequence_domains.domain = websites_categories.domain\n",
    "GROUP BY user_sequence_domains.domain, 2\n",
    ")\n",
    "SELECT category, domain, CAST(total_events AS INT) as total_events\n",
    "FROM prebase_domains_categories\n",
    "ORDER BY total_events DESC\n",
    "LIMIT 50;\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a treemap with plotly\n",
    "fig = px.treemap(\n",
    "    child_treemap,\n",
    "    path=['category', 'domain'],\n",
    "    values='total_events',\n",
    "    color='total_events',\n",
    "    color_continuous_scale='RdBu',\n",
    "    title='Treemap of domains',\n",
    "    hover_data=['total_events'],\n",
    "    color_continuous_midpoint=np.average(child_treemap['total_events'], weights=child_treemap['total_events'])\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top urls visited as last touch before tripadvisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duck_con.execute(\"\"\"SELECT url, COUNT(0) as count \n",
    "FROM user_sequence\n",
    "WHERE reverse_sequence = 1\n",
    "GROUP BY url\n",
    "ORDER BY count DESC\n",
    "LIMIT 10;\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duck_con.execute(\"\"\"SELECT domain, COUNT(0) as count \n",
    "FROM user_sequence_domains\n",
    "WHERE reverse_sequence = 1\n",
    "GROUP BY domain\n",
    "ORDER BY count DESC\n",
    "LIMIT 10;\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duck_con.execute(\"\"\"SELECT *\n",
    "FROM user_sequence\n",
    "WHERE url like '%tripadvisor%'\n",
    "ORDER BY userid, sequence\n",
    "LIMIT 10;\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size of journeys to tripadvisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journeys = duck_con.execute(\n",
    "    \"\"\"SELECT userid,\n",
    "    COUNT(0) AS total_steps\n",
    "FROM user_sequence\n",
    "GROUP BY userid;\"\"\"\n",
    ").df()\n",
    "journeys.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_journeys = duck_con.execute(\n",
    "    \"\"\"SELECT userid,\n",
    "    COUNT(0) AS total_steps\n",
    "FROM user_sequence_domains\n",
    "GROUP BY userid;\"\"\"\n",
    ").df()\n",
    "domain_journeys.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top last 10 steps journey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journey_last_10_steps = duck_con.execute(\"\"\"SELECT *\n",
    "FROM user_sequence_domains\n",
    "WHERE reverse_sequence <= 10\n",
    "ORDER BY userid, sequence;\"\"\"\n",
    ").df()\n",
    "\n",
    "journey_last_10_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journey_last_10_steps[journey_last_10_steps['domain'] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journey_last_10_steps.pivot(\n",
    "    index='userid', columns='reverse_sequence', values='domain'\n",
    ").reset_index().info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dataframe from row to column getting values using reverse_sequence as column name and values as domain\n",
    "journey = journey_last_10_steps.pivot(\n",
    "    index='userid', columns='reverse_sequence', values='domain'\n",
    ").reset_index()\n",
    "journey.columns = ['userid', 'step_10', 'step_9', 'step_8', 'step_7', 'step_6', 'step_5', 'step_4', 'step_3', 'step_2', 'step_1']\n",
    "journey\n",
    "\n",
    "# convert journey dataframe to get top 10 most common journeys\n",
    "unique_journeys = dict()\n",
    "for index, row in journey.iterrows():\n",
    "    only_steps = row[1:]\n",
    "    only_steps = only_steps.values.tolist()\n",
    "    only_steps = tuple(only_steps)\n",
    "\n",
    "    if only_steps in unique_journeys:\n",
    "        unique_journeys[only_steps] += 1\n",
    "    else:\n",
    "        unique_journeys[only_steps] = 1\n",
    "\n",
    "unique_journeys = pd.DataFrame.from_dict(unique_journeys, orient='index').reset_index()\n",
    "unique_journeys.columns = ['journey', 'count']\n",
    "unique_journeys = unique_journeys.sort_values(by='count', ascending=False)\n",
    "unique_journeys.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot top 10 most common journeys using plotly and sankey diagram\n",
    "fig = go.Figure(data=[go.Sankey(\n",
    "    node=dict(\n",
    "        pad=15,\n",
    "        thickness=20,\n",
    "        line=dict(color=\"black\", width=0.5),\n",
    "        label=journey.columns[1:],\n",
    "        color=\"blue\"\n",
    "    ),\n",
    "    link=dict(\n",
    "        source=[0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        target=[1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "        value=unique_journeys['count']\n",
    "    )\n",
    ")])\n",
    "\n",
    "fig.update_layout(title_text=\"Top 10 most common journeys\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
